import os
import json
import argparse
import asyncio
import logging
import re
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple
from io import BytesIO
from collections import deque

import httpx
from httpx import HTTPStatusError, ReadTimeout, Timeout
from PIL import Image

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π –≤ posted.json ---
MAX_POSTED_RECORDS = 200 # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ ID –≤ posted.json
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
HTTPX_TIMEOUT = Timeout(connect=10.0, read=60.0, write=10.0, pool=5.0)
MAX_RETRIES   = 3
RETRY_DELAY   = 5.0
DEFAULT_DELAY = 10.0 # –ò–∑–º–µ–Ω–µ–Ω —Å 5.0 –Ω–∞ 10.0, –∫–∞–∫ –≤ –≤–∞—à–µ–π –≤–µ—Ä—Å–∏–∏

def escape_markdown(text: str) -> str:
    """
    –≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã –¥–ª—è MarkdownV2, –∫—Ä–æ–º–µ –∑–≤–µ–∑–¥–æ—á–∫–∏ (*), –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∂–∏—Ä–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
    """
    # –£–¥–∞–ª—è–µ–º '*' –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –∂–∏—Ä–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
    markdown_chars = r'\_[]()~`>#+-=|{}.!'
    return re.sub(r'([%s])' % re.escape(markdown_chars), r'\\\1', text)

def chunk_text(text: str, size: int = 4096) -> List[str]:
    """
    –î–µ–ª–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ –¥–ª–∏–Ω–æ–π <= size, —Å–æ—Ö—Ä–∞–Ω—è—è –∞–±–∑–∞—Ü—ã.
    –≠–¢–ê –í–ï–†–°–ò–Ø –§–£–ù–ö–¶–ò–ò –í–ó–Ø–¢–ê –ò–ó –í–ê–®–ï–ì–û –ü–†–ï–î–û–°–¢–ê–í–õ–ï–ù–ù–û–ì–û –ö–û–î–ê, –¢–ê–ö –ö–ê–ö –û–ù–ê –ë–û–õ–ï–ï –ì–ò–ë–ö–ê–Ø.
    """
    norm = text.replace('\r\n', '\n')
    paras = [p for p in norm.split('\n\n') if p.strip()]
    chunks, curr = [], ""

    def split_long(p: str) -> List[str]:
        parts, sub = [], ""
        for w in p.split(" "):
            if len(sub) + len(w) + 1 > size:
                parts.append(sub)
                sub = w
            else:
                sub = (sub + " " + w).lstrip()
        if sub:
            parts.append(sub)
        return parts

    for p in paras:
        if len(p) > size:
            if curr:
                chunks.append(curr)
                curr = ""
            chunks.extend(split_long(p))
        else:
            if not curr:
                curr = p
            elif len(curr) + 2 + len(p) <= size:
                curr += "\n\n" + p
            else:
                chunks.append(curr)
                curr = p

    if curr:
        chunks.append(curr)
    return chunks


def apply_watermark(img_path: Path, scale: float = 0.45) -> bytes:
    """
    –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ—Ç watermark.png –≤ –ø—Ä–∞–≤—ã–π –≤–µ—Ä—Ö–Ω–∏–π —É–≥–æ–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –æ—Ç—Å—Ç—É–ø–æ–º.
    –î–û–ü–û–õ–ù–ï–ù–ò–Ø: –î–æ–±–∞–≤–ª–µ–Ω—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ –≤–æ–¥—è–Ω–æ–≥–æ –∑–Ω–∞–∫–∞ –∏ –æ–±—â–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫.
    """
    try:
        base_img = Image.open(img_path).convert("RGBA")
        base_width, base_height = base_img.size

        script_dir = Path(__file__).parent
        watermark_path = script_dir / "watermark.png"
        if not watermark_path.exists():
            logging.warning("Watermark file not found at %s. Skipping watermark.", watermark_path)
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª, –µ—Å–ª–∏ –Ω–µ—Ç –≤–æ–¥—è–Ω–æ–≥–æ –∑–Ω–∞–∫–∞
            img_byte_arr = BytesIO()
            base_img.save(img_byte_arr, format='PNG')
            return img_byte_arr.getvalue()

        watermark_img = Image.open(watermark_path).convert("RGBA")

        # Resize watermark
        wm_width, wm_height = watermark_img.size
        new_wm_width = int(base_width * scale)
        new_wm_height = int(wm_height * (new_wm_width / wm_width))
        filt = getattr(Image.Resampling, "LANCZOS", Image.LANCZOS) # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –≤–µ—Ä—Å–∏–π Pillow
        watermark_img = watermark_img.resize((new_wm_width, new_wm_height), resample=filt)

        # Create a transparent overlay
        overlay = Image.new("RGBA", base_img.size, (0, 0, 0, 0))

        # Position watermark (top-right, with some padding)
        padding = int(base_width * 0.02) # 2% padding –æ—Ç –≤–∞—à–µ–π –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏
        position = (base_width - new_wm_width - padding, padding)
        overlay.paste(watermark_img, position, watermark_img)

        # Composite the images –¥–ª—è –ª—É—á—à–µ–≥–æ —Å–º–µ—à–∏–≤–∞–Ω–∏—è
        composite_img = Image.alpha_composite(base_img, overlay)

        # Save to bytes
        img_byte_arr = BytesIO()
        composite_img.save(img_byte_arr, format='PNG') # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ PNG
        return img_byte_arr.getvalue()
    except Exception as e:
        logging.error(f"Failed to apply watermark to {img_path}: {e}")
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
        try:
            img_byte_arr = BytesIO()
            Image.open(img_path).save(img_byte_arr, format='PNG')
            return img_byte_arr.getvalue()
        except Exception as e_orig:
            logging.error(f"Failed to load original image {img_path} after watermark error: {e_orig}")
            return b"" # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ –±–∞–π—Ç—ã, –µ—Å–ª–∏ –¥–∞–∂–µ –æ—Ä–∏–≥–∏–Ω–∞–ª –Ω–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å


async def _post_with_retry(
    client: httpx.AsyncClient,
    method: str,
    url: str,
    data: Dict[str, Any],
    files: Optional[Dict[str, Any]] = None
) -> bool:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç HTTP POST-–∑–∞–ø—Ä–æ—Å —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π 429 Too Many Requests.
    –í–ê–®–ê –í–ï–†–°–ò–Ø –§–£–ù–ö–¶–ò–ò, –ü–†–ò–ù–Ø–¢–ê –ö–ê–ö –ë–û–õ–ï–ï –ì–ò–ë–ö–ê–Ø –ò –° –î–ï–¢–ê–õ–¨–ù–´–ú –õ–û–ì–ò–†–û–í–ê–ù–ò–ï–ú.
    """
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º data= –∏ files= –≤–º–µ—Å—Ç–æ json= –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ multipart/form-data
            resp = await client.request(method, url, data=data, files=files, timeout=HTTPX_TIMEOUT)
            resp.raise_for_status()
            return True

        except ReadTimeout:
            logging.warning("‚è± Timeout %s/%s for %s", attempt, MAX_RETRIES, url)

        except HTTPStatusError as e:
            code = e.response.status_code
            text = e.response.text
            if code == 429:
                # Telegram –ø—Ä–∏—Å—ã–ª–∞–µ—Ç retry_after –≤ JSON-–ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö
                info = e.response.json().get("parameters", {})
                wait = info.get("retry_after", RETRY_DELAY)
                logging.warning("üê¢ Rate limited %s/%s: retry after %s seconds", attempt, MAX_RETRIES, wait)
                await asyncio.sleep(wait)
                continue # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø–æ–ø—ã—Ç–∫–∏ –ø–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è
            if 400 <= code < 500:
                logging.error("‚ùå %s %s: %s", method, code, text)
                return False # –î–ª—è –∫–ª–∏–µ–Ω—Ç—Å–∫–∏—Ö –æ—à–∏–±–æ–∫ –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–µ–º
            logging.warning("‚ö†Ô∏è %s %s, retry %s/%s", method, code, attempt, MAX_RETRIES)
        except httpx.RequestError as e: # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥—Ä—É–≥–∏—Ö —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–æ–∫ httpx
            logging.warning(f"Request error on attempt {attempt + 1}/{MAX_RETRIES}: {e}")
        except Exception as e:
            logging.error(f"An unexpected error occurred on attempt {attempt + 1}/{MAX_RETRIES}: {e}")

        await asyncio.sleep(RETRY_DELAY)

    logging.error("‚ò†Ô∏è Failed %s after %s attempts", url, MAX_RETRIES)
    return False


async def send_media_group(
    client: httpx.AsyncClient,
    token: str,
    chat_id: str,
    images: List[Path]
) -> bool:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∞–ª—å–±–æ–º —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –±–µ–∑ –ø–æ–¥–ø–∏—Å–∏.
    –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ—Ö–æ–¥—è—Ç —á–µ—Ä–µ–∑ apply_watermark.
    –î–û–ü–û–õ–ù–ï–ù–ò–Ø: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –º–µ–¥–∏–∞–≥—Ä—É–ø–ø—ã Telegram.
    """
    url   = f"https://api.telegram.org/bot{token}/sendMediaGroup"
    media = []
    files = {}
    photo_count = 0

    if not images:
        logging.warning("No images provided for media group.")
        return False

    for idx, img_path in enumerate(images):
        if photo_count >= 10: # Telegram limit for media groups
            logging.warning("Telegram media group limit (10 images) reached. Skipping remaining images.")
            break
        try:
            image_bytes = apply_watermark(img_path)
            if not image_bytes:
                logging.warning(f"Skipping image {img_path} due to empty bytes after watermark processing.")
                continue

            key = f"file{idx}"
            files[key] = (img_path.name, image_bytes, "image/png") # img_path.name –¥–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            media.append({
                "type": "photo",
                "media": f"attach://{key}"
            })
            photo_count += 1
        except Exception as e:
            logging.error(f"Error processing image {img_path} for media group: {e}")
            # –ù–µ –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

    if not media:
        logging.warning("No valid images to send in media group after processing.")
        return False

    data = {
        "chat_id": chat_id,
        "media": json.dumps(media, ensure_ascii=False)
    }
    return await _post_with_retry(client, "POST", url, data, files)


async def send_message(
    client: httpx.AsyncClient,
    token: str,
    chat_id: str,
    text: str
) -> bool:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ä–∞–∑–±–æ—Ä–æ–º MarkdownV2.
    """
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    data = {
        "chat_id": chat_id,
        "text": escape_markdown(text),
        "parse_mode": "MarkdownV2",
        "disable_web_page_preview": True # –û–±—ã—á–Ω–æ –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è —Å—Ç–∞—Ç–µ–π
    }
    return await _post_with_retry(client, "POST", url, data)


def validate_article(
    art: Dict[str, Any],
    article_dir: Path
) -> Optional[Tuple[str, Path, List[Path]]]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–∫–∏ —Å—Ç–∞—Ç—å–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
    –í–ê–®–ê –í–ï–†–°–ò–Ø –§–£–ù–ö–¶–ò–ò, –ü–†–ò–ù–Ø–¢–ê –ö–ê–ö –ë–û–õ–ï–ï –ù–ê–î–ï–ñ–ù–ê–Ø.
    """
    aid      = art.get("id")
    title    = art.get("title", "").strip()
    txt_name = Path(art.get("text_file", "")).name if art.get("text_file") else None # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ None
    imgs     = art.get("images", [])

    if not title:
        logging.error("Invalid title for article in %s (ID: %s). Skipping.", article_dir, aid)
        return None

    # –ü–æ–∏—Å–∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
    text_path: Optional[Path] = None
    if txt_name:
        candidate_path = article_dir / txt_name
        if candidate_path.is_file():
            text_path = candidate_path
    
    if not text_path: # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ text_file –∏–ª–∏ –µ–≥–æ –Ω–µ –±—ã–ª–æ
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç RU-—Ñ–∞–π–ª—É, –∑–∞—Ç–µ–º EN, –∑–∞—Ç–µ–º –ª—é–±–æ–π txt
        if (article_dir / "content.ru.txt").is_file():
            text_path = article_dir / "content.ru.txt"
        elif (article_dir / "content.txt").is_file():
            text_path = article_dir / "content.txt"
        else:
            candidates = list(article_dir.glob("*.txt"))
            if candidates:
                text_path = candidates[0] # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π txt

    if not text_path or not text_path.is_file():
        logging.error("No text file found for article in %s (ID: %s). Skipping.", article_dir, aid)
        return None

    # –°–±–æ—Ä –∫–∞—Ä—Ç–∏–Ω–æ–∫
    valid_imgs: List[Path] = []
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Ç–∏ –∏–∑ meta.json
    for name in imgs:
        p = article_dir / Path(name).name # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –∏–º—è —Ñ–∞–π–ª–∞ –≤ images —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ —Ñ–∞–π–ª –≤ –∫–æ—Ä–Ω–µ —Å—Ç–∞—Ç—å–∏
        if not p.is_file():
            p = article_dir / "images" / Path(name).name # –ò–ª–∏ –≤ –ø–æ–¥–ø–∞–ø–∫–µ 'images'
        if p.is_file():
            valid_imgs.append(p)

    # –ï—Å–ª–∏ –ø–æ –ø—É—Ç—è–º –∏–∑ meta.json –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—â–µ–º –≤ –ø–æ–¥–ø–∞–ø–∫–µ 'images'
    if not valid_imgs:
        imgs_dir = article_dir / "images"
        if imgs_dir.is_dir():
            valid_imgs = [
                p for p in imgs_dir.iterdir()
                if p.suffix.lower() in (".jpg", ".jpeg", ".png")
            ]
        # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤—Å–µ –µ—â–µ –Ω–µ—Ç, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç–∞—Ç—å—è –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        # logging.warning("No images found for article in %s (ID: %s). Proceeding without images.", article_dir, aid)
        # –í –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–µ—Ç, send_media_group –≤–µ—Ä–Ω–µ—Ç False, –∏ –º—ã –ø–µ—Ä–µ–π–¥–µ–º –∫ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ç–µ–∫—Å—Ç–∞.


    # –ü–æ–¥–ø–∏—Å—å –¥–ª—è –º–µ–¥–∏–∞–≥—Ä—É–ø–ø—ã/—Å–æ–æ–±—â–µ–Ω–∏—è (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ 1024 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è –º–µ–¥–∏–∞–≥—Ä—É–ø–ø, –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏–π 4096)
    # –ó–¥–µ—Å—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—â–µ–π –ø–æ–¥–ø–∏—Å–∏, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
    cap = title if len(title) <= 1024 else title[:1023] + "‚Ä¶" # –û–±—Ä–µ–∑–∞–µ–º —Å –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ–º –¥–ª—è –ø–æ–¥–ø–∏—Å–∏ –∫ –º–µ–¥–∏–∞
    
    return cap, text_path, valid_imgs


def load_posted_ids(state_file: Path) -> Set[int]:
    """
    –ß–∏—Ç–∞–µ—Ç state-—Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç set –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö ID.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
      - –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π –∏–ª–∏ –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª
      - —Å–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª [1,2,3]
      - —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ [{"id":1}, {"id":2}]
    –í–ê–®–ê –í–ï–†–°–ò–Ø –§–£–ù–ö–¶–ò–ò, –ü–†–ò–ù–Ø–¢–ê –ö–ê–ö –ë–û–õ–ï–ï –ù–ê–î–ï–ñ–ù–ê–Ø.
    """
    if not state_file.is_file():
        logging.info("State file %s not found. Returning empty set.", state_file)
        return set()

    text = state_file.read_text(encoding="utf-8").strip()
    if not text:
        logging.warning("State file %s is empty. Returning empty set.", state_file)
        return set()

    try:
        data = json.loads(text)
    except json.JSONDecodeError:
        logging.warning("State file %s is not valid JSON. Returning empty set.", state_file)
        return set()

    if not isinstance(data, list):
        logging.warning("State file %s content is not a list. Returning empty set.", state_file)
        return set()

    ids: Set[int] = set()
    for item in data:
        if isinstance(item, dict) and "id" in item:
            try:
                ids.add(int(item["id"]))
            except (ValueError, TypeError):
                logging.warning("Invalid ID format in state file: %s. Skipping.", item)
                pass
        elif isinstance(item, (int, str)) and str(item).isdigit():
            ids.add(int(item))
        else:
            logging.warning("Unexpected item type in state file: %s. Skipping.", item)
    return ids


def save_posted_ids(all_ids_to_save: Set[int], state_file: Path) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö ID —Å—Ç–∞—Ç–µ–π –≤ —Ñ–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è.
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–∞–∫—Å–∏–º—É–º MAX_POSTED_RECORDS, –¥–æ–±–∞–≤–ª—è—è –Ω–æ–≤—ã–µ –≤ –Ω–∞—á–∞–ª–æ –∏ –≤—ã—Ç–µ—Å–Ω—è—è —Å—Ç–∞—Ä—ã–µ –≤ –∫–æ–Ω—Ü–µ.
    –≠–¢–ê –§–£–ù–ö–¶–ò–Ø –û–°–¢–ê–ï–¢–°–Ø –ö–ê–ö –í –ü–†–ï–î–´–î–£–©–ï–ú –†–ï–®–ï–ù–ò–ò, –ü–õ–Æ–° –ò–ú–ü–û–†–¢ `deque`.
    """
    state_file.parent.mkdir(parents=True, exist_ok=True) # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â–∏–µ ID –∏–∑ —Ñ–∞–π–ª–∞ (–¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞ –∏ –∏–∑–±–µ–≥–∞–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)
    current_ids_list: deque = deque()
    if state_file.exists():
        try:
            with state_file.open("r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, list):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ ID, –∏–≥–Ω–æ—Ä–∏—Ä—É—è —Å—Ç–∞—Ä—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Å –æ–±—ä–µ–∫—Ç–∞–º–∏
                    for item in data:
                        if isinstance(item, dict) and "id" in item:
                            current_ids_list.append(item["id"])
                        elif isinstance(item, int):
                            current_ids_list.append(item)
                else:
                    logging.warning(f"State file {state_file} has unexpected format. Starting with fresh records.")
        except json.JSONDecodeError:
            logging.warning(f"State file {state_file} is corrupted. Starting with fresh records.")
        except Exception as e:
            logging.error(f"Error reading existing state file {state_file}: {e}. Starting with fresh records.")

    # 2. –°–æ–∑–¥–∞–µ–º Set –∏–∑ —Ç–µ–∫—É—â–∏—Ö ID –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    current_ids_set = set(current_ids_list)

    # 3. –û–±—ä–µ–¥–∏–Ω—è–µ–º –Ω–æ–≤—ã–µ ID —Å —Ç–µ–∫—É—â–∏–º–∏, –¥–æ–±–∞–≤–ª—è—è –Ω–æ–≤—ã–µ –≤ –Ω–∞—á–∞–ª–æ
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º deque –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –Ω–∞—á–∞–ª–æ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞
    temp_ids_deque = deque(maxlen=MAX_POSTED_RECORDS)

    # –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ ID, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –±—ã–ª–æ —Ä–∞–Ω–µ–µ
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ ID –≤ —É–±—ã–≤–∞—é—â–µ–º –ø–æ—Ä—è–¥–∫–µ, —á—Ç–æ–±—ã –±–æ–ª–µ–µ –Ω–æ–≤—ã–µ ID (–µ—Å–ª–∏ –æ–Ω–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ)
    # –ø–æ–ø–∞–¥–∞–ª–∏ –≤ –Ω–∞—á–∞–ª–æ –æ—á–µ—Ä–µ–¥–∏ –ø–µ—Ä–≤—ã–º–∏, –µ—Å–ª–∏ –∏—Ö –±—ã–ª–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤ —Ç–µ–∫—É—â–µ–º –±–∞—Ç—á–µ.
    for aid in sorted(list(all_ids_to_save - current_ids_set), reverse=True):
        temp_ids_deque.appendleft(aid)

    # –ó–∞—Ç–µ–º –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ ID, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –±—ã–ª–∏ –≤ —Ñ–∞–π–ª–µ –∏ –Ω–µ –±—ã–ª–∏ —Ç–æ–ª—å–∫–æ —á—Ç–æ –¥–æ–±–∞–≤–ª–µ–Ω—ã
    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ —Å—Ç–∞—Ä—ã–º ID –≤ —Ç–æ–º –ø–æ—Ä—è–¥–∫–µ, –≤ –∫–æ—Ç–æ—Ä–æ–º –æ–Ω–∏ –±—ã–ª–∏ –≤ —Ñ–∞–π–ª–µ
    for aid in current_ids_list:
        if aid in all_ids_to_save: # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ ID –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –∏—Ç–æ–≥–æ–≤–æ–º —Å–ø–∏—Å–∫–µ (—Ç.–µ. –Ω–µ –æ—Ç–±—Ä–æ—à–µ–Ω)
            if aid not in temp_ids_deque: # –ò–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è, –µ—Å–ª–∏ –Ω–æ–≤—ã–π ID —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å–æ —Å—Ç–∞—Ä—ã–º
                temp_ids_deque.append(aid)

    # temp_ids_deque –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ä–µ–∑–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –¥–æ MAX_POSTED_RECORDS,
    # —É–¥–∞–ª—è—è —ç–ª–µ–º–µ–Ω—Ç—ã —Å –∫–æ–Ω—Ü–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –≤ –Ω–∞—á–∞–ª–æ.

    # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ ID –≤ —Ñ–∞–π–ª
    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º deque –æ–±—Ä–∞—Ç–Ω–æ –≤ list –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        final_list_to_save = list(temp_ids_deque)
        with state_file.open("w", encoding="utf-8") as f:
            json.dump(final_list_to_save, f, ensure_ascii=False, indent=2)
        logging.info(f"Saved {len(final_list_to_save)} IDs to state file {state_file} (max {MAX_POSTED_RECORDS}).")
    except Exception as e:
        logging.error(f"Failed to save state file {state_file}: {e}")


async def main(parsed_dir: str, state_path: str, limit: Optional[int]):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–æ—Å—Ç–µ—Ä–∞.
    """
    token       = os.getenv("TELEGRAM_TOKEN")
    chat_id     = os.getenv("TELEGRAM_CHANNEL")
    if not token or not chat_id:
        logging.error("TELEGRAM_TOKEN or TELEGRAM_CHANNEL environment variables must be set.")
        return

    delay       = float(os.getenv("POST_DELAY", DEFAULT_DELAY))
    parsed_root = Path(parsed_dir)
    state_file  = Path(state_path)

    if not parsed_root.is_dir():
        logging.error("Parsed directory %s does not exist. Exiting.", parsed_root)
        return

    # 1) –ó–∞–≥—Ä—É–∑–∫–∞ —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö ID
    posted_ids_old = load_posted_ids(state_file)
    logging.info("Loaded %d previously posted IDs from %s.", len(posted_ids_old), state_file.name)

    # 2) –°–±–æ—Ä –ø–∞–ø–æ–∫ —Å–æ —Å—Ç–∞—Ç—å—è–º–∏ –∏ –∏—Ö –≤–∞–ª–∏–¥–∞—Ü–∏—è
    articles_to_post: List[Dict[str, Any]] = []
    for d in sorted(parsed_root.iterdir()): # –ò—Ç–µ—Ä–∏—Ä—É–µ–º –ø–æ –ø–∞–ø–∫–∞–º
        meta_file = d / "meta.json"
        if d.is_dir() and meta_file.is_file():
            try:
                art_meta = json.loads(meta_file.read_text(encoding="utf-8"))
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ ID —Å—Ç–∞—Ç—å–∏ –µ—â–µ –Ω–µ –±—ã–ª –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω
                if art_meta.get("id") is not None and art_meta["id"] not in posted_ids_old:
                    validated_data = validate_article(art_meta, d)
                    if validated_data:
                        # –î–æ–±–∞–≤–ª—è–µ–º ID –≤ –¥–∞–Ω–Ω—ã–µ, —á—Ç–æ–±—ã –ø–µ—Ä–µ–¥–∞—Ç—å –µ–≥–æ –¥–∞–ª—å—à–µ
                        validated_data_dict = {
                            "id": art_meta["id"],
                            "caption": validated_data[0],
                            "text_path": validated_data[1],
                            "image_paths": validated_data[2]
                        }
                        articles_to_post.append(validated_data_dict)
                    else:
                        logging.warning("Article metadata validation failed for %s. Skipping.", d.name)
                elif art_meta.get("id") is not None:
                    logging.debug("Skipping already posted article ID=%s.", art_meta["id"])
                else:
                    logging.warning("Article in %s has no ID in meta.json. Skipping.", d.name)
            except json.JSONDecodeError as e:
                logging.warning("Cannot load or parse meta.json in %s: %s. Skipping.", d.name, e)
            except Exception as e:
                logging.error("An unexpected error occurred while processing article %s: %s. Skipping.", d.name, e)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ç—å–∏ –ø–æ ID –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ article["id"] —è–≤–ª—è–µ—Ç—Å—è —á–∏—Å–ª–æ–º
    articles_to_post.sort(key=lambda x: x["id"])

    if not articles_to_post:
        logging.info("üîç No new articles to post. Exiting.")
        return

    logging.info("Found %d new articles to consider for posting.", len(articles_to_post))

    client    = httpx.AsyncClient()
    sent      = 0
    new_ids: Set[int] = set() # ID, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ —É—Å–ø–µ—à–Ω–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω—ã –≤ —Ç–µ–∫—É—â–µ–º –∑–∞–ø—É—Å–∫–µ

    # 3) –ü—É–±–ª–∏–∫–∞—Ü–∏—è –∫–∞–∂–¥–æ–π —Å—Ç–∞—Ç—å–∏
    for article in articles_to_post:
        if limit is not None and sent >= limit:
            logging.info("Batch limit of %d reached. Stopping.", limit)
            break

        aid       = article["id"]
        caption   = article["caption"]
        text_path = article["text_path"]
        image_paths = article["image_paths"]

        logging.info("Attempting to post ID=%s", aid)
        
        posted_successfully = False
        try:
            # 3.1) –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å).
            if image_paths:
                if not await send_media_group(client, token, chat_id, image_paths):
                    logging.warning("Failed to send media group for ID=%s. Proceeding to send text only (title already in text).", aid)
                    # –ï—Å–ª–∏ –º–µ–¥–∏–∞–≥—Ä—É–ø–ø–∞ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞.
                    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º —Å—Ä–∞–∑—É –∫ –æ—Ç–ø—Ä–∞–≤–∫–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
                else:
                    # –ï—Å–ª–∏ –º–µ–¥–∏–∞–≥—Ä—É–ø–ø–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞, –∑–¥–µ—Å—å –ù–ï –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.
                    # –ù–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º, —Ç–∞–∫ –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–µ –¥–æ–ª–∂–µ–Ω –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ.
                    pass
            else:
                # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–µ—Ç —Å–æ–≤—Å–µ–º, –ù–ï –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.
                logging.info("No images for ID=%s. Proceeding to send text only (title already in text).", aid)
                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º —Å—Ä–∞–∑—É –∫ –æ—Ç–ø—Ä–∞–≤–∫–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
            
            # 3.2) –¢–µ–ª–æ —Å—Ç–∞—Ç—å–∏ –ø–æ —á–∞–Ω–∫–∞–º
            raw_text = text_path.read_text(encoding="utf-8")
            chunks = chunk_text(raw_text)
            all_chunks_sent = True
            for part in chunks:
                if not await send_message(client, token, chat_id, part):
                    logging.error("Failed to send a text chunk for ID=%s. Skipping remaining chunks and article.", aid)
                    all_chunks_sent = False
                    break
            
            if all_chunks_sent:
                posted_successfully = True

        except Exception as e:
            logging.error(f"‚ùå An error occurred during posting article ID={aid}: {e}. Moving to next article.")
            posted_successfully = False # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ñ–ª–∞–≥ —Å–±—Ä–æ—à–µ–Ω –ø—Ä–∏ –æ—à–∏–±–∫–µ

        if posted_successfully:
            new_ids.add(aid) # –î–æ–±–∞–≤–ª—è–µ–º –≤ Set –Ω–æ–≤—ã—Ö —É—Å–ø–µ—à–Ω–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö ID
            sent += 1
            logging.info("‚úÖ Posted ID=%s", aid)
        
        await asyncio.sleep(delay)

    await client.aclose()

    # 4) –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ ID
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç–∞—Ä—ã–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ ID —Å –Ω–æ–≤—ã–º–∏, —É—Å–ø–µ—à–Ω–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–º–∏ –≤ —ç—Ç–æ–º –∑–∞–ø—É—Å–∫–µ
    all_ids_to_save = posted_ids_old.union(new_ids)
    save_posted_ids(all_ids_to_save, state_file)
    logging.info("State updated. Total unique IDs to be saved: %d.", len(all_ids_to_save))
    logging.info("üì¢ Done: sent %d articles in this run.", sent)

if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description="Poster: –ø—É–±–ª–∏–∫—É–µ—Ç —Å—Ç–∞—Ç—å–∏ –ø–∞–∫–µ—Ç–∞–º–∏ –≤ Telegram"
    )
    parser.add_argument(
        "--parsed-dir",
        type=str,
        default="articles", # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫ –∏—Å—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        help="–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–º–∏ —Å—Ç–∞—Ç—å—è–º–∏"
    )
    parser.add_argument(
        "--state-file",
        type=str,
        default="articles/posted.json", # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É —Å–æ—Å—Ç–æ—è–Ω–∏—è
        help="–ø—É—Ç—å –∫ state-—Ñ–∞–π–ª—É"
    )
    parser.add_argument(
        "-n", "--limit",
        type=int,
        default=None,
        help="–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏"
    )

    args = parser.parse_args()

    asyncio.run(main(
        parsed_dir=args.parsed_dir,
        state_path=args.state_file,
        limit=args.limit
    ))