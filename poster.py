import os
import json
import argparse
import asyncio
import logging
import re
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple
from io import BytesIO
from collections import deque

import httpx
from httpx import HTTPStatusError, ReadTimeout, Timeout
from PIL import Image

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π –≤ posted.json ---
MAX_POSTED_RECORDS = 200 # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ ID –≤ posted.json
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
HTTPX_TIMEOUT = Timeout(connect=10.0, read=60.0, write=10.0, pool=5.0)
MAX_RETRIES   = 3
RETRY_DELAY   = 5.0
DEFAULT_DELAY = 10.0

def escape_html(text: str) -> str:
    """
    –≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã HTML (<, >, &, ") –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Telegram —Å parse_mode='HTML'.
    –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –¥–æ–ª–∂–µ–Ω –ø—Ä–∏–º–µ–Ω—è—Ç—å—Å—è –∫ –°–´–†–û–ú–£ —Ç–µ–∫—Å—Ç—É, –∫–æ—Ç–æ—Ä—ã–π –ù–ï –Ø–í–õ–Ø–ï–¢–°–Ø HTML-—Ç–µ–≥–∞–º–∏.
    """
    # –ó–∞–º–µ–Ω—è–µ–º —Å–∏–º–≤–æ–ª—ã –Ω–∞ –∏—Ö HTML-—Å—É—â–Ω–æ—Å—Ç–∏
    text = text.replace("&", "&amp;")
    text = text.replace("<", "&lt;")
    text = text.replace(">", "&gt;")
    text = text.replace('"', "&quot;")
    return text

def chunk_text(text: str, size: int = 4096) -> List[str]:
    """
    –î–µ–ª–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ –¥–ª–∏–Ω–æ–π <= size, —Å–æ—Ö—Ä–∞–Ω—è—è –∞–±–∑–∞—Ü—ã.
    """
    norm = text.replace('\r\n', '\n')
    paras = [p for p in norm.split('\n\n') if p.strip()]
    chunks, curr = [], ""

    def split_long(p: str) -> List[str]:
        parts, sub = [], ""
        for w in p.split(" "):
            if len(sub) + len(w) + 1 > size:
                parts.append(sub)
                sub = w
            else:
                sub = (sub + " " + w).lstrip()
        if sub:
            parts.append(sub)
        return parts

    for p in paras:
        if len(p) > size:
            if curr:
                chunks.append(curr)
                curr = ""
            chunks.extend(split_long(p))
        else:
            if not curr:
                curr = p
            elif len(curr) + 2 + len(p) <= size:
                curr += "\n\n" + p
            else:
                chunks.append(curr)
                curr = p

    if curr:
        chunks.append(curr)
    return chunks


def apply_watermark(img_path: Path, scale: float = 0.45) -> bytes:
    """
    –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ—Ç watermark.png –≤ –ø—Ä–∞–≤—ã–π –≤–µ—Ä—Ö–Ω–∏–π —É–≥–æ–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –æ—Ç—Å—Ç—É–ø–æ–º.
    """
    try:
        base_img = Image.open(img_path).convert("RGBA")
        base_width, base_height = base_img.size

        script_dir = Path(__file__).parent
        watermark_path = script_dir / "watermark.png"
        if not watermark_path.exists():
            logging.warning("Watermark file not found at %s. Skipping watermark.", watermark_path)
            img_byte_arr = BytesIO()
            base_img.save(img_byte_arr, format='PNG')
            return img_byte_arr.getvalue()

        watermark_img = Image.open(watermark_path).convert("RGBA")

        wm_width, wm_height = watermark_img.size
        new_wm_width = int(base_width * scale)
        new_wm_height = int(wm_height * (new_wm_width / wm_width))
        filt = getattr(Image.Resampling, "LANCZOS", Image.LANCZOS)
        watermark_img = watermark_img.resize((new_wm_width, new_wm_height), resample=filt)

        overlay = Image.new("RGBA", base_img.size, (0, 0, 0, 0))

        padding = int(base_width * 0.02)
        position = (base_width - new_wm_width - padding, padding)
        overlay.paste(watermark_img, position, watermark_img)

        composite_img = Image.alpha_composite(base_img, overlay)

        img_byte_arr = BytesIO()
        composite_img.save(img_byte_arr, format='PNG')
        return img_byte_arr.getvalue()
    except Exception as e:
        logging.error(f"Failed to apply watermark to {img_path}: {e}")
        try:
            img_byte_arr = BytesIO()
            Image.open(img_path).save(img_byte_arr, format='PNG')
            return img_byte_arr.getvalue()
        except Exception as e_orig:
            logging.error(f"Failed to load original image {img_path} after watermark error: {e_orig}")
            return b""


async def _post_with_retry(
    client: httpx.AsyncClient,
    method: str,
    url: str,
    data: Dict[str, Any],
    files: Optional[Dict[str, Any]] = None
) -> bool:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç HTTP POST-–∑–∞–ø—Ä–æ—Å —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π 429 Too Many Requests.
    """
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            resp = await client.request(method, url, data=data, files=files, timeout=HTTPX_TIMEOUT)
            resp.raise_for_status()
            return True

        except ReadTimeout:
            logging.warning("‚è± Timeout %s/%s for %s", attempt, MAX_RETRIES, url)
        except HTTPStatusError as e:
            code = e.response.status_code
            text = e.response.text
            if code == 429:
                info = e.response.json().get("parameters", {})
                wait = info.get("retry_after", RETRY_DELAY)
                logging.warning("üê¢ Rate limited %s/%s: retry after %s seconds", attempt, MAX_RETRIES, wait)
                await asyncio.sleep(wait)
                continue
            if 400 <= code < 500:
                logging.error("‚ùå %s %s: %s", method, code, text)
                return False
            logging.warning("‚ö†Ô∏è %s %s, retry %s/%s", method, code, attempt, MAX_RETRIES)
        except httpx.RequestError as e:
            logging.warning(f"Request error on attempt {attempt + 1}/{MAX_RETRIES}: {e}")
        except Exception as e:
            logging.error(f"An unexpected error occurred on attempt {attempt + 1}/{MAX_RETRIES}: {e}")

        await asyncio.sleep(RETRY_DELAY)

    logging.error("‚ò†Ô∏è Failed %s after %s attempts", url, MAX_RETRIES)
    return False


async def send_media_group(
    client: httpx.AsyncClient,
    token: str,
    chat_id: str,
    images: List[Path]
) -> bool:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∞–ª—å–±–æ–º —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –±–µ–∑ –ø–æ–¥–ø–∏—Å–∏ (–ø–æ–¥–ø–∏—Å—å –±—É–¥–µ—Ç –≤ –ø–µ—Ä–≤–æ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–º —á–∞–Ω–∫–µ).
    –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ—Ö–æ–¥—è—Ç —á–µ—Ä–µ–∑ apply_watermark.
    –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –º–µ–¥–∏–∞–≥—Ä—É–ø–ø—ã Telegram.
    """
    url   = f"https://api.telegram.org/bot{token}/sendMediaGroup"
    media = []
    files = {}
    photo_count = 0

    if not images:
        logging.warning("No images provided for media group.")
        return False

    for idx, img_path in enumerate(images):
        if photo_count >= 10:
            logging.warning("Telegram media group limit (10 images) reached. Skipping remaining images.")
            break
        try:
            image_bytes = apply_watermark(img_path)
            if not image_bytes:
                logging.warning(f"Skipping image {img_path} due to empty bytes after watermark processing.")
                continue

            key = f"file{idx}"
            files[key] = (img_path.name, image_bytes, "image/png")

            media_item = {
                "type": "photo",
                "media": f"attach://{key}"
            }
            media.append(media_item)
            photo_count += 1
        except Exception as e:
            logging.error(f"Error processing image {img_path} for media group: {e}")

    if not media:
        logging.warning("No valid images to send in media group after processing.")
        return False

    data = {
        "chat_id": chat_id,
        "media": json.dumps(media, ensure_ascii=False)
    }
    return await _post_with_retry(client, "POST", url, data, files)


async def send_message(
    client: httpx.AsyncClient,
    token: str,
    chat_id: str,
    text: str,
    reply_markup: Optional[Dict[str, Any]] = None
) -> bool:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ä–∞–∑–±–æ—Ä–æ–º HTML.
    –¢–µ–∫—Å—Ç, –ø–µ—Ä–µ–¥–∞–≤–∞–µ–º—ã–π –≤ —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é, –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É–∂–µ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω –∏ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω –¥–ª—è HTML.
    –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–Ω–æ–ø–∫–∏ (inline keyboard).
    """
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    data = {
        "chat_id": chat_id,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": True
    }
    if reply_markup:
        data["reply_markup"] = json.dumps(reply_markup, ensure_ascii=False)
    return await _post_with_retry(client, "POST", url, data)


def validate_article(
    art: Dict[str, Any],
    article_dir: Path
) -> Optional[Tuple[str, Path, List[Path], str]]: # –î–æ–±–∞–≤–ª–µ–Ω –≤–æ–∑–≤—Ä–∞—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–∫–∏ —Å—Ç–∞—Ç—å–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç HTML-–æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫, –ø—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É,
    —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º –∏ –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ô –Ω–µ—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫.
    """
    aid      = art.get("id")
    title    = art.get("title", "").strip() # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π, –Ω–µ—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    txt_name = Path(art.get("text_file", "")).name if art.get("text_file") else None

    if not title:
        logging.error("Invalid title for article in %s (ID: %s). Skipping.", article_dir, aid)
        return None

    # –ü–æ–∏—Å–∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
    text_path: Optional[Path] = None
    if txt_name:
        candidate_path = article_dir / txt_name
        if candidate_path.is_file():
            text_path = candidate_path
    
    if not text_path:
        if (article_dir / "content.ru.txt").is_file():
            text_path = article_dir / "content.ru.txt"
        elif (article_dir / "content.txt").is_file():
            text_path = article_dir / "content.txt"
        else:
            candidates = list(article_dir.glob("*.txt"))
            if candidates:
                text_path = candidates[0]

    if not text_path or not text_path.is_file():
        logging.error("No text file found for article in %s (ID: %s). Skipping.", article_dir, aid)
        return None

    # –°–±–æ—Ä –∫–∞—Ä—Ç–∏–Ω–æ–∫
    valid_imgs: List[Path] = []
    for name in art.get("images", []):
        p = article_dir / Path(name).name
        if not p.is_file():
            p = article_dir / "images" / Path(name).name
        if p.is_file():
            valid_imgs.append(p)

    if not valid_imgs:
        imgs_dir = article_dir / "images"
        if imgs_dir.is_dir():
            valid_imgs = [
                p for p in imgs_dir.iterdir()
                if p.suffix.lower() in (".jpg", ".jpeg", ".png")
            ]

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –≤ HTML-—Ñ–æ—Ä–º–∞—Ç–µ (–∂–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç)
    html_title = f"<b>{escape_html(title)}</b>"
    
    return html_title, text_path, valid_imgs, title # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫


def load_posted_ids(state_file: Path) -> Set[int]:
    """
    –ß–∏—Ç–∞–µ—Ç state-—Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç set –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö ID.
    """
    if not state_file.is_file():
        logging.info("State file %s not found. Returning empty set.", state_file)
        return set()

    text = state_file.read_text(encoding="utf-8").strip()
    if not text:
        logging.warning("State file %s is empty. Returning empty set.", state_file)
        return set()

    try:
        data = json.loads(text)
    except json.JSONDecodeError:
        logging.warning("State file %s is not valid JSON. Returning empty set.", state_file)
        return set()

    if not isinstance(data, list):
        logging.warning("State file %s content is not a list. Returning empty set.", state_file)
        return set()

    ids: Set[int] = set()
    for item in data:
        if isinstance(item, dict) and "id" in item:
            try:
                ids.add(int(item["id"]))
            except (ValueError, TypeError):
                logging.warning("Invalid ID format in state file: %s. Skipping.", item)
                pass
        elif isinstance(item, (int, str)) and str(item).isdigit():
            ids.add(int(item))
        else:
            logging.warning("Unexpected item type in state file: %s. Skipping.", item)
    return ids


def save_posted_ids(all_ids_to_save: Set[int], state_file: Path) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö ID —Å—Ç–∞—Ç–µ–π –≤ —Ñ–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è.
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–∞–∫—Å–∏–º—É–º MAX_POSTED_RECORDS, –¥–æ–±–∞–≤–ª—è—è –Ω–æ–≤—ã–µ –≤ –Ω–∞—á–∞–ª–æ –∏ –≤—ã—Ç–µ—Å–Ω—è—è —Å—Ç–∞—Ä—ã–µ –≤ –∫–æ–Ω—Ü–µ.
    """
    state_file.parent.mkdir(parents=True, exist_ok=True)

    current_ids_list: deque = deque()
    if state_file.exists():
        try:
            with state_file.open("r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, list):
                    for item in data:
                        if isinstance(item, dict) and "id" in item:
                            current_ids_list.append(item["id"])
                        elif isinstance(item, int):
                            current_ids_list.append(item)
                else:
                    logging.warning(f"State file {state_file} has unexpected format. Starting with fresh records.")
        except json.JSONDecodeError:
            logging.warning(f"State file {state_file} is corrupted. Starting with fresh records.")
        except Exception as e:
            logging.error(f"Error reading existing state file {state_file}: {e}. Starting with fresh records.")

    current_ids_set = set(current_ids_list)

    temp_ids_deque = deque(maxlen=MAX_POSTED_RECORDS)

    for aid in sorted(list(all_ids_to_save - current_ids_set), reverse=True):
        temp_ids_deque.appendleft(aid)

    for aid in current_ids_list:
        if aid in all_ids_to_save:
            if aid not in temp_ids_deque:
                temp_ids_deque.append(aid)

    try:
        final_list_to_save = list(temp_ids_deque)
        with state_file.open("w", encoding="utf-8") as f:
            json.dump(final_list_to_save, f, ensure_ascii=False, indent=2)
        logging.info(f"Saved {len(final_list_to_save)} IDs to state file {state_file} (max {MAX_POSTED_RECORDS}).")
    except Exception as e:
        logging.error(f"Failed to save state file {state_file}: {e}")


async def main(parsed_dir: str, state_path: str, limit: Optional[int]):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–æ—Å—Ç–µ—Ä–∞.
    """
    token       = os.getenv("TELEGRAM_TOKEN")
    chat_id     = os.getenv("TELEGRAM_CHANNEL")
    if not token or not chat_id:
        logging.error("TELEGRAM_TOKEN –∏–ª–∏ TELEGRAM_CHANNEL –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.")
        return

    delay       = float(os.getenv("POST_DELAY", DEFAULT_DELAY))
    parsed_root = Path(parsed_dir)
    state_file  = Path(state_path)

    if not parsed_root.is_dir():
        logging.error("–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è %s –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –í—ã—Ö–æ–¥.", parsed_root)
        return

    # 1) –ó–∞–≥—Ä—É–∑–∫–∞ —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö ID
    posted_ids_old = load_posted_ids(state_file)
    logging.info("–ó–∞–≥—Ä—É–∂–µ–Ω–æ %d —Ä–∞–Ω–µ–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö ID –∏–∑ %s.", len(posted_ids_old), state_file.name)

    # 2) –°–±–æ—Ä –ø–∞–ø–æ–∫ —Å–æ —Å—Ç–∞—Ç—å—è–º–∏ –∏ –∏—Ö –≤–∞–ª–∏–¥–∞—Ü–∏—è
    articles_to_post: List[Dict[str, Any]] = []
    for d in sorted(parsed_root.iterdir()):
        meta_file = d / "meta.json"
        if d.is_dir() and meta_file.is_file():
            try:
                art_meta = json.loads(meta_file.read_text(encoding="utf-8"))
                if art_meta.get("id") is not None and art_meta["id"] not in posted_ids_old:
                    validated_data = validate_article(art_meta, d)
                    if validated_data:
                        # –†–∞–∑–±–∏—Ä–∞–µ–º –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ, –≤–∫–ª—é—á–∞—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
                        html_title, text_path, image_paths, original_plain_title = validated_data
                        validated_data_dict = {
                            "id": art_meta["id"],
                            "html_title": html_title,
                            "text_path": text_path,
                            "image_paths": image_paths,
                            "original_plain_title": original_plain_title # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
                        }
                        articles_to_post.append(validated_data_dict)
                    else:
                        logging.warning("–í–∞–ª–∏–¥–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç—å–∏ –Ω–µ —É–¥–∞–ª–∞—Å—å –¥–ª—è %s. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.", d.name)
                elif art_meta.get("id") is not None:
                    logging.debug("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—É—é —Å—Ç–∞—Ç—å—é ID=%s.", art_meta["id"])
                else:
                    logging.warning("–°—Ç–∞—Ç—å—è –≤ %s –Ω–µ –∏–º–µ–µ—Ç ID –≤ meta.json. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.", d.name)
            except json.JSONDecodeError as e:
                logging.warning("–ù–µ —É–¥–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–ª–∏ —Ä–∞–∑–æ–±—Ä–∞—Ç—å meta.json –≤ %s: %s. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.", d.name, e)
            except Exception as e:
                logging.error("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç–∞—Ç—å–∏ %s: %s. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.", d.name, e)
    
    articles_to_post.sort(key=lambda x: x["id"])

    if not articles_to_post:
        logging.info("üîç –ù–µ—Ç –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏. –í—ã—Ö–æ–¥.")
        return

    logging.info("–ù–∞–π–¥–µ–Ω–æ %d –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π –¥–ª—è —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è –∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏.", len(articles_to_post))

    client    = httpx.AsyncClient()
    sent      = 0
    new_ids: Set[int] = set()

    # 3) –ü—É–±–ª–∏–∫–∞—Ü–∏—è –∫–∞–∂–¥–æ–π —Å—Ç–∞—Ç—å–∏
    for article in articles_to_post:
        if limit is not None and sent >= limit:
            logging.info("–õ–∏–º–∏—Ç –ø–∞—á–∫–∏ –≤ %d –¥–æ—Å—Ç–∏–≥–Ω—É—Ç. –û—Å—Ç–∞–Ω–æ–≤–∫–∞.", limit)
            break

        aid         = article["id"]
        html_title  = article["html_title"]
        text_path   = article["text_path"]
        image_paths = article["image_paths"]
        original_plain_title = article["original_plain_title"] # –ü–æ–ª—É—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫

        logging.info("–ü–æ–ø—ã—Ç–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ ID=%s", aid)
        
        posted_successfully = False
        try:
            # 3.1) –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å) –ë–ï–ó –ü–û–î–ü–ò–°–ò
            if image_paths:
                if not await send_media_group(client, token, chat_id, image_paths):
                    logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –º–µ–¥–∏–∞–≥—Ä—É–ø–ø—É –¥–ª—è ID=%s. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç.", aid)
            
            # 3.2) –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: HTML-–∑–∞–≥–æ–ª–æ–≤–æ–∫ + –æ—á–∏—â–µ–Ω–Ω–æ–µ –∏ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç–∞—Ç—å–∏
            raw_text = text_path.read_text(encoding="utf-8")

            cleaned_raw_text = raw_text
            if original_plain_title:
                # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–º –≤—ã—Ä–∞–∂–µ–Ω–∏–∏
                escaped_plain_title_for_regex = re.escape(original_plain_title)
                
                # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –≤ –Ω–∞—á–∞–ª–µ —Ç–µ–∫—Å—Ç–∞,
                # –∑–∞ –∫–æ—Ç–æ—Ä—ã–º —Å–ª–µ–¥—É—é—Ç –æ–¥–∏–Ω –∏–ª–∏ –±–æ–ª–µ–µ –ø—Ä–æ–±–µ–ª–æ–≤/–Ω–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫.
                # re.DOTALL –ø–æ–∑–≤–æ–ª—è–µ—Ç '.' —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Å–∏–º–≤–æ–ª–∞–º –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏.
                # re.IGNORECASE –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–µ–Ω, –µ—Å–ª–∏ —Ä–µ–≥–∏—Å—Ç—Ä –∑–∞–≥–æ–ª–æ–≤–∫–∞ –≤ —Ñ–∞–π–ª–µ –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è.
                pattern = re.compile(rf"^{escaped_plain_title_for_regex}\s*", re.DOTALL | re.IGNORECASE)

                match = pattern.match(raw_text)
                if match:
                    cleaned_raw_text = raw_text[match.end():] # –û–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –≤—Å–µ—Ö –ø—Ä–æ–±–µ–ª–æ–≤/newlines
                else:
                    # –ï—Å–ª–∏ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞—à–ª–æ —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è,
                    # —ç—Ç–æ –º–æ–∂–µ—Ç –æ–∑–Ω–∞—á–∞—Ç—å, —á—Ç–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ,
                    # –∏–ª–∏ –µ—Å—Ç—å –Ω–µ–±–æ–ª—å—à–∏–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è. –í—ã–≤–æ–¥–∏–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ.
                    logging.warning(
                        f"–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ '{original_plain_title}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –Ω–∞—á–∞–ª–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è ID={aid}. "
                        "–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏–∑ meta.json."
                    )
                    cleaned_raw_text = raw_text # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –∫–∞–∫ –µ—Å—Ç—å

            escaped_raw_text = escape_html(cleaned_raw_text)
            full_html_content = f"{html_title}\n\n{escaped_raw_text}"
            
            # 3.3) –î–µ–ª–∏–º –Ω–∞ —á–∞–Ω–∫–∏
            chunks = chunk_text(full_html_content)
            num_chunks = len(chunks)

            all_chunks_sent = True
            for i, part in enumerate(chunks):
                current_reply_markup = None
                if i == num_chunks - 1: # –ï—Å–ª–∏ —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫, –¥–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫–∏
                    keyboard = {
                        "inline_keyboard": [
                            [
                                {"text": "–û–±–º–µ–Ω –≤–∞–ª—é—Ç", "url": "https://t.me/mister1dollar"},
                                {"text": "–û—Ç–∑—ã–≤—ã", "url": "https://t.me/feedback1dollar"}
                            ]
                        ]
                    }
                    current_reply_markup = keyboard

                if not await send_message(client, token, chat_id, part, reply_markup=current_reply_markup):
                    logging.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π —á–∞–Ω–∫ –¥–ª—è ID=%s. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —á–∞–Ω–∫–∏ –∏ —Å—Ç–∞—Ç—å—é.", aid)
                    all_chunks_sent = False
                    break
            
            if all_chunks_sent:
                posted_successfully = True

        except Exception as e:
            logging.error(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å—Ç–∞—Ç—å–∏ ID={aid}: {e}. –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç–∞—Ç—å–µ.")
            posted_successfully = False

        if posted_successfully:
            new_ids.add(aid)
            sent += 1
            logging.info("‚úÖ –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ ID=%s", aid)
        
        await asyncio.sleep(delay)

    await client.aclose()

    # 4) –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ ID
    all_ids_to_save = posted_ids_old.union(new_ids)
    save_posted_ids(all_ids_to_save, state_file)
    logging.info("–°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–æ. –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: %d.", len(all_ids_to_save))
    logging.info("üì¢ –ó–∞–≤–µ—Ä—à–µ–Ω–æ: –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ %d —Å—Ç–∞—Ç–µ–π –≤ —ç—Ç–æ–º –∑–∞–ø—É—Å–∫–µ.", sent)

if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description="Poster: –ø—É–±–ª–∏–∫—É–µ—Ç —Å—Ç–∞—Ç—å–∏ –ø–∞–∫–µ—Ç–∞–º–∏ –≤ Telegram"
    )
    parser.add_argument(
        "--parsed-dir",
        type=str,
        default="articles",
        help="–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–º–∏ —Å—Ç–∞—Ç—å—è–º–∏"
    )
    parser.add_argument(
        "--state-file",
        type=str,
        default="articles/posted.json",
        help="–ø—É—Ç—å –∫ state-—Ñ–∞–π–ª—É"
    )
    parser.add_argument(
        "-n", "--limit",
        type=int,
        default=None,
        help="–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏"
    )

    args = parser.parse_args()

    asyncio.run(main(
        parsed_dir=args.parsed_dir,
        state_path=args.state_file,
        limit=args.limit
    ))
